{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Install the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What’s happening here?**\n",
    "\n",
    "This is like telling your computer: \"Hey, I need to download some special software so I can work with AI models.\"\n",
    "\n",
    "**Libraries Explained:**\n",
    "\n",
    "transformers: Helps us use pre-trained AI language models.\n",
    "\n",
    "gradio: A tool for building simple web interfaces (we’re not using it in this version but it's installed in case).\n",
    "\n",
    "torch: A library that helps the AI model do calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\python310\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: gradio in c:\\python310\\lib\\site-packages (5.34.2)\n",
      "Requirement already satisfied: torch in c:\\python310\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\python310\\lib\\site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: requests in c:\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\python310\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python310\\lib\\site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python310\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\python310\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\python310\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: ffmpy in c:\\python310\\lib\\site-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\python310\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\python310\\lib\\site-packages (from gradio) (0.115.13)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\python310\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\python310\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\python310\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\python310\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\python310\\lib\\site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\python310\\lib\\site-packages (from gradio) (1.4.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\python310\\lib\\site-packages (from gradio) (4.14.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\python310\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\python310\\lib\\site-packages (from gradio) (0.34.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\python310\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\python310\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\python310\\lib\\site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\python310\\lib\\site-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in c:\\python310\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\python310\\lib\\site-packages (from gradio) (9.2.0)\n",
      "Requirement already satisfied: gradio-client==1.10.3 in c:\\python310\\lib\\site-packages (from gradio) (1.10.3)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\python310\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\python310\\lib\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\python310\\lib\\site-packages (from gradio-client==1.10.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: fsspec in c:\\python310\\lib\\site-packages (from gradio-client==1.10.3->gradio) (2025.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python310\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\python310\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python310\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python310\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python310\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: certifi in c:\\python310\\lib\\site-packages (from httpx>=0.24.1->gradio) (2022.6.15.1)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\python310\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\python310\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python310\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python310\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\python310\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\python310\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\python310\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python310\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python310\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers gradio torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers gradio torch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Install the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What’s happening here?**\n",
    "\n",
    "This is like opening your toolbox and saying: \"I’m ready to use these AI tools.\"\n",
    "\n",
    "**Libraries Explained**\n",
    "\n",
    "AutoTokenizer: Prepares text so the AI can understand it.\n",
    "\n",
    "AutoModelForCausalLM: Loads the AI brain (the model that generates text).\n",
    "\n",
    "pipeline: A shortcut to make using the model super easy.\n",
    "\n",
    "torch: Helps the AI run efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What’s happening here?**\n",
    "\n",
    "We’re downloading a ready-made AI model called TinyLlama.\n",
    "(Think of TinyLlama as a smaller version of the AI used in chatbots like ChatGPT.)\n",
    "\n",
    "**Tools Used Explained**\n",
    "\n",
    "tokenizer: Turns our questions into something the AI can read.\n",
    "\n",
    "model: The AI brain that gives us answers.\n",
    "\n",
    "pipeline: Creates a simple way to ask the AI questions.\n",
    "\n",
    "device=0 if torch.cuda.is_available() else -1:\n",
    "This line says: \"Use the computer’s graphics card (if available) for faster answers, otherwise just use the normal processor.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Using a lightweight model for fast local inference\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Create text-generation pipeline\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1  # Use GPU if available, else CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Define the AI career coach function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What’s happening here?**\n",
    "\n",
    "This is like writing the instructions for the AI: \"Here’s what I want you to do.\"\n",
    "\n",
    "We tell the AI: \"Pretend you are a friendly career coach. Help this student find a good career based on their interests and personality.\"\n",
    "\n",
    "**Tools Used Explained**\n",
    "\n",
    "prompt: This is the question we’re asking the AI. It’s like giving the AI a story setup.\n",
    "\n",
    "generator: This sends the prompt to the AI and asks it to write a response.\n",
    "\n",
    "max_length=300: Limits the answer to about 300 words so it’s not too long.\n",
    "\n",
    "do_sample=True: Makes sure the answer is a little different each time, not just copied.\n",
    "\n",
    "temperature=0.7: Controls the creativity of the answer (lower = more predictable, higher = more creative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_career_advice(name, interests, personality_traits):\n",
    "    prompt = f\"\"\"\n",
    "You are a friendly and insightful AI career coach for high school students. A student named {name} has come to you for advice. They are interested in {interests} and describe themselves as {personality_traits}.\n",
    "\n",
    "Give them a thoughtful career suggestion and explain why it suits them. Keep your tone encouraging and clear.\n",
    "\"\"\"\n",
    "    response = generator(prompt, max_length=300, do_sample=True, temperature=0.7)\n",
    "    return response[0][\"generated_text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Example use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What’s happening here?**\n",
    "\n",
    "We’re giving the AI an example student: Alex.\n",
    "\n",
    "We tell the AI what Alex is interested in and what kind of person they are.\n",
    "\n",
    "We then ask the AI to give Alex career advice.\n",
    "\n",
    "print() shows the AI’s advice on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Career Coach says:\n",
      "\n",
      "\n",
      "You are a friendly and insightful AI career coach for high school students. A student named Alex has come to you for advice. They are interested in technology, sports, and building things and describe themselves as curious, practical, hands-on.\n",
      "\n",
      "Give them a thoughtful career suggestion and explain why it suits them. Keep your tone encouraging and clear.\n",
      "\n",
      "Suggestion:\n",
      "As a technology enthusiast and sports lover, Alex's skills and interests align perfectly with the rapidly evolving field of AI. With their aptitude for coding and problem-solving, they would excel in the field of AI software development.\n",
      "\n",
      "You can provide them with an opportunity to work on an ongoing project that involves using AI to create customized sports analytics. This would enable them to gain practical experience in designing and implementing AI solutions to real-world problems. They would also have the opportunity to work with senior AI engineers who can provide them with guidance and mentorship.\n",
      "\n",
      "This experience would provide Alex with a unique opportunity to learn from experienced professionals, develop their skills, and gain a deeper understanding of the field of AI. It would also provide them with a valuable skill set that would help them stand out in the job market.\n",
      "\n",
      "Overall, your support and guidance would help Alex gain the skills, experience, and confidence they need to pursue their passion for AI.\n"
     ]
    }
   ],
   "source": [
    "# Example student input\n",
    "name = \"Alex\"\n",
    "interests = \"technology, sports, and building things\"\n",
    "personality_traits = \"curious, practical, hands-on\"\n",
    "\n",
    "# Generate advice\n",
    "advice = generate_career_advice(name, interests, personality_traits)\n",
    "print(\"\\nAI Career Coach says:\\n\")\n",
    "print(advice)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
